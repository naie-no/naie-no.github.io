*februar 5, 2026 – Wessel Braakman*

Den 2. februar ble Norsk AI-Etikkforening (NAIE) lansert.
Samme dag var det seks måneder igjen til sentrale deler av EUs AI Act trer i kraft.

Blant de mange bestemmelsene finner vi artikkel 10, som krever identifisering av skjevheter i høyrisiko KI-systemer. Skjevhetene må reduseres der det er mulig. Videre følger et krav om overvåking etter at et system er tatt i bruk.

## Artikkel 10: KI-etikk fra teori til praksis

![Artikkel 10](/blog/seks-maneder-igjen-ai-act-artikkel-10/1-artikkel.png)
![Artikkel 10](/blog/seks-maneder-igjen-ai-act-artikkel-10/2-artikkel.png)

[Artikkel 10 ](https://artificialintelligenceact.eu/article/10/) stiller krav til at datasett i slike KI-systemer er relevante og representative. Og dermed er ikke KI-etikk lenger en frivillig øvelse. For mange organisasjoner vil artikkel 10 by på operative utfordringer, hvor det blant annet må avklares:

Hva betyr skjevhet i vårt system? 
Hvordan kan vi faktisk avdekke den? 
Hvor ofte bør vi teste? 
Hva skjer når et system endrer seg over tid? 

Dette er ikke bare juridiske spørsmål. De påvirker utvikling, testing og drift. Og spørsmålene har ingen enkle svar.

## Seks måneder er ikke lang tid

Mens vinter blir til vår og sommeren svinner hen, må norske virksomheter få på plass:

- en felles forståelse av hva skjevhet innebærer 
- tester som går utover ytelse og nøyaktighet 
- rutiner for overvåking etter produksjonssetting 
- en klar idé om hva som er tilstrekkelig praksis 

Bremseklossene for en slik gjennomgang trenger ikke dreie seg om manglende vilje. Det kan handle om manglende metoder, få referansepunkter og begrenset erfaringsutveksling, spesielt i en norsk kontekst.

## Formålet med NAIE

![Artikkel 10](/blog/seks-maneder-igjen-ai-act-artikkel-10/3-blog.png)

Norsk AI-Etikkforening har allerede erfaring med testing av skjevhet i språkmodeller, med fokus på norsk språk og kultur. Vi er åpne om våre metoder og tilgjengeliggjør våre funn løpende, blant annet i en blogg med analyser basert på et større datasett.

![Artikkel 10](/blog/seks-maneder-igjen-ai-act-artikkel-10/4-blog.png)

NAIE er opprettet for å videreføre vårt allerede pågående arbeid på en mer transparent og strukturert måte. Vi sitter ikke med en fasit, men vi deler åpent våre erfaringer med å måle skjevheter i KI-systemer.

Artikkel 10 handler om å bygge KI-systemer som virksomheter og befolkningen har tillit til over tid. NAIE bidrar med metode for å implementere etikk i praksis.
