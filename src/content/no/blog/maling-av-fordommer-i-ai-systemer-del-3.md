*februar 11, 2026  ‚Äì Wessel Braakman*
> Ingen LLM/GenKI ble brukt til √• skrive denne bloggen üôÇ

## Innledning

I de tidligere blogginnleggene i denne serien introduserte vi ideen om √• bygge en slags **norsk AI Bias Indicator**, hvor vi oversetter **Bias Benchmark for Question Answering (BBQ)** til norsk kontekst og spr√•k, og delte v√•re f√∏rste, forel√∏pige resultater. M√•let har v√¶rt det samme fra starten av: √• forst√• hvordan skjevhet i store spr√•kmodeller p√•virkes av spr√•k og kulturell kontekst, og √• finne en transparent og reproduserbar m√•te √• m√•le denne skjevheten p√• i Norge.

Prosjektet endret seg betydelig siden del 2. Det som startet som et lite eksperiment har blitt mer strukturert og mer datadrevet. Vi har utvidet datasettet (fortsatt manuelt), testet flere modeller, utviklet valideringsmetoder og startet samarbeid med b√•de internasjonale forskere og norske institusjoner.

Samtidig har prosjektet f√•tt et mer solid forankring. Arbeidet
gjennomf√∏res n√• under paraplyen til **Norsk AI-Etikkforening (NAIE), en ideell organisasjon med fokus p√• ansvarlig og etisk bruk av AI i Norge**.

√Ö v√¶re en del av NAIE betyr noe. Det gir arbeidet et tydeligere fundament og en sterkere uavhengighet. Dette er ikke en kommersiell benchmark eller en produktsammenligning, men et forskningsdrevet arbeid styrt av et felles m√•l om √• forbedre transparens, rettferdighet og ansvarlighet i AI-systemer brukt i en norsk kontekst.

## Fra 40 til 400+ prompter

I den aller f√∏rste fasen jobbet vi med kun 10 prompter i fire
kategorier, noe som resulterte i **40 oversatte og tilpassede sp√∏rsm√•l**. Det var nok til √• komme i gang og avdekke noen interessante m√∏nstre, men det var ogs√• sv√¶rt begrensende. Med s√• f√• prompter er det vanskelig √• si noe om nyanser, variasjon eller konsistens.

De siste m√•nedene har vi manuelt utvidet datasettet til rundt 100 prompts innenfor disse fire kategoriene, noe som gir oss **mer enn 400 prompts totalt**.

![Progress](/blog/maling-av-fordommer-i-ai-systemer-del-3/1-progress.png)

Denne √∏kningen har gjort det mulig √• utforske dimensjonen av fordommer innenfor kategorier som kj√∏nn, alder og nasjonalitet, gjennom et langt bredere spekter av formuleringer, tone og kontekst.

Norsk er ikke et enkelt spr√•k √• teste. To skriftlige standarder, sterke dialektvariasjoner og mange implisitte kulturelle referanser gj√∏r at sm√• endringer i ordlyd kan f√• stor betydning. Ved √• utvide datasettet har vi begynt √• fange mer av denne kompleksiteten. Det gir oss et langt bedre grunnlag for √• sammenligne modeller og for √• forst√• hvor og hvordan skjevhet oppst√•r. Vi fokuserer forel√∏pig kun p√• bokm√•l, men vil teste AI-systemer mot nynorsk n√•r vi har fullf√∏rt v√•r f√∏rste komplette iterasjon.

Denne utvidelsen er ogs√• et steg p√• veien mot neste m√•l: et omfattende datasett p√• rundt 3 000 prompter for hver av de fire opprinnelige kategorier, f√∏r vi til slutt bygger et fullstendig datasett p√• rundt 3000 prompter for hver av de totalt 11 kategorier. De siste utvidelsene vil bli gjennomf√∏rt ved hjelp av maler og skript, p√• samme m√•te som de opprinnelige BBQ-forskerne genererte sine datasett.

## Testing av flere modeller

I del 2 fokuserte vi hovedsakelig p√• prosess, hvordan g√• fra kontekst ogsp√∏rsm√•l til ferdig prompt, hvordan sende dem inn og hvordan evaluere svarene. Som i del 2 kj√∏rte vi det utvidede datasettet mot **ChatGPT**, **Gemini** og **Perplexity**, tre modeller med ulike bakgrunner, treningsdata og designvalg.

![LLM](/blog/maling-av-fordommer-i-ai-systemer-del-3/2-llm.png

Noen modeller falt ofte tilbake p√• sv√¶rt forsiktige svar som ¬´det kan ikke avgj√∏res¬ª, mens andre var mer bastante og til tider tydelig mindre n√∏ytrale. Vi la ogs√• merke til at norske sp√∏rsm√•l ikke alltid ga like tydelige svar, spesielt n√•r promptet bygget p√• subtile sosiale eller kulturelle signaler fremfor eksplisitt informasjon.

Den opprinnelige BBQ-forskningen ble gjennomf√∏rt p√• et langt tidligere stadium i utviklingen av LLM-er. Det betydde at **promptene som ble sendt inn ikke var √•pne sp√∏rsm√•l, men inkluderte tre svaralternativer**. Modellene m√•tte da velge ett av disse tre. I v√•rt tilfelle stilte vi **√•pne sp√∏rsm√•l**, noe som f√∏rte til at en modell av og til svarte **¬´b√•de 1 og 2¬ª**, eller til og med kom med et alternativ **¬´4¬ª** der vi forventet ett av tre. Dette skapte mer kompleksitet, men inneb√¶rer ogs√• at vi ikke mater systemet med ferdige svaralternativer som kan p√•virke eller styre responsen.

## Scoring: automatisering med menneskelig kontroll

Etter √• ha samlet inn modellresponsene, var neste utfordring √• evaluere dem, alts√• √• avgj√∏re om et svar samsvarte med den n√∏ytrale eller forventede etiketten.

Vi brukte en hybrid tiln√¶rming:

-   **Automatisert scoring**, der skript mapper svarene til forh√•ndsdefinerte alternativer, ans0, ans1, ans2.
-   **Manuell scoring** for svar som var tvetydige, indirekte eller sterkt kontekstavhengige.

![Scoring](/blog/maling-av-fordommer-i-ai-systemer-del-3/3-scoring.png)
![Scoring](/blog/maling-av-fordommer-i-ai-systemer-del-3/4-scoring.png)

**Automatiseringen** gjorde det mulig √• **h√•ndtere omfanget av datasettet**, mens **manuell gjennomgang** sikret at **spr√•klige nyanser og norske s√¶rtrekk ikke ble jevnet ut eller feiltolket**. Kombinasjonen ga oss et klarere bilde av overordnede trender, for eksempel n√•r modeller systematisk heller mot n√∏ytralitet eller konsekvent knytter bestemte demografiske trekk til bestemte utfall.

## Samarbeid og faglig forankring

Underveis har vi hatt l√∏pende samtaler med forskere og organisasjoner som arbeider med skjevhet og AI-etikk.

Vi har hatt stor nytte av diskusjoner med **Alicia Parrish**, en av skaperne av det opprinnelige BBQ-datasettet og forskningen bak. Hennes tilbakemeldinger b√•de bekreftet og utfordret deler av v√•r norske tilpasning.
Vi har ogs√• diskutert tiln√¶rmingen v√•r med **Kathinka Vik** (n√• styremedlem i foreningen) fra Likestillings- og diskrimineringsombudet (LDO), noe som har hjulpet oss √• koble de tekniske funnene til reelle samfunnssp√∏rsm√•l om diskriminering og rettferdighet.
I tillegg har vi delt tanker og erfaringer med **Mascha Kurpicz-Briki** og hennes kolleger i **The Bias Project**.

Disse utvekslingene er viktige for oss. De bidrar til at arbeidet b√•de er metodisk solid og samfunnsmessig relevant. Gjennom NAIE er m√•let ikke bare √• m√•le skjevhet, men √• bruke innsikten til √• st√∏tte en mer ansvarlig og transparent bruk av AI i Norge.

## Forel√∏pige resultater

![Graph](/blog/maling-av-fordommer-i-ai-systemer-del-3/5-graph.png)
\% Skjevhetsavvik per kategori per LLM\
Kilde: NoBBQ metode, populasjon ‚âÖ 100 prompts, 2025-09-07

Figuren over viser forel√∏pige avvik i skjevhet per kategori og modell, basert p√• omtrent 100 prompts per kategori ved bruk av NoBBQ-metoden. **Selv om datasettet fortsatt er begrenset i st√∏rrelse, ser vi allerede tydelige forskjeller mellom modellene innen kategorier som kj√∏nnsidentitet, alder, nasjonalitet og religion.**

Vi observerer at enkelte modeller konsekvent viser h√∏yere avvik i spesifikke kategorier, mens andre oftere faller tilbake p√• n√∏ytrale eller ubestemmelige svar. M√∏nstrene tyder p√• at skjevhet ikke manifesterer seg likt overalt, men varierer b√•de mellom modeller og mellom ulike sosiale kategorier.

Resultatene b√∏r leses som **utforskende** snarere enn **konkluderende**. De gir et **tidlig signal om hvordan norsk spr√•k og kontekst p√•virker modellatferd**, og de hjelper oss **√• identifisere hvor det er st√∏rst behov for dypere analyser og videre utvidelse av datasettet**. En mer detaljert forklaring av metodikk, evalueringsprosess og begrensninger finnes p√• resultatsiden.

## Hva skjer videre: skalering og automatisering

Med et st√∏rre datasett, flere modeller og en mer robust evalueringsprosess p√• plass, er vi klare for neste fase.

V√•re hovedprioriteringer er:

-   √Ö **utvide datasettet** videre mot rundt 3 000 prompts for hvert av v√•re fire opprinnelige skjevhetskategorier, for √• bedre gjenspeile bredden av situasjoner AI-systemer m√∏ter.\
-   √Ö **automatisere mer av prosessen**, fra generering av prompter basert p√• maler, til h√•ndtering av prompter, modellforesp√∏rsler og evaluering, slik at NoBBQ blir repeterbar og b√¶rekraftig over tid.

![Plan](/blog/maling-av-fordommer-i-ai-systemer-del-3/6-plan.png)

M√•let er √• **bevege oss bort fra enkeltst√•ende evalueringer** og over mot **kontinuerlig overv√•king**. Det vil gj√∏re oss i stand til √• f√∏lge endringer p√• tvers av modellversjoner, sammenligne systemer over tid og se om nye versjoner faktisk forbedrer eller forverrer skjevhetsrelatert atferd.

Vi utforsker ogs√• tettere samarbeid med norske akademiske milj√∏er og europeiske initiativer, inkludert BIAS-prosjektet ved NTNU, for √• plassere arbeidet v√•rt i et bredere forskningslandskap.

## Refleksjoner: √• informere og √• inspirere

Helt fra starten har prosjektet hatt to ambisjoner:

For det f√∏rste √• **informere**, ved √• gj√∏re skjevhet i AI-systemer synlig og m√•lbar.
For det andre √• **inspirere**, ved √• vise at seri√∏s og etisk AI-forskning kan gjennomf√∏res lokalt, p√• norsk og for norske kontekster.

Det som startet som et lite eksperiment har vokst til et langsiktig arbeid med rettferdighet i AI som kjerne. En av de tydeligste l√¶rdommene s√• langt er at rettferdighet ikke kan tas for gitt. Den m√• bli testet, revurderet og forbedret kontinuerlig.

Mens vi arbeider videre med √• fullf√∏re NoBBQ-forskningen, er kjerneoppdraget uendret: √• bidra til at AI-systemer brukt i Norge gjenspeiler verdiene om likhet, mangfold og rettferdighet som samfunnet v√•rt bygger p√•.

## Takk

Vi vil rette en stor takk til **Alicia Parrish, Kathinka Theodore Aakenes Vik, Mascha Kurpicz-Briki, The BIAS Project** og alle andre som har bidratt gjennom diskusjoner, tilbakemeldinger og samarbeid.

**NoBBQ** er n√• et p√•g√•ende forskningsarbeid innen **Norsk AI-Etikkforening (NAIE)**, der vi fortsetter √• utvikle verkt√∏y, innsikt og rammeverk for ansvarlig AI i Norge.

Hvis du er interessert i √• f√∏lge arbeidet eller bidra i kommende faser, h√∏rer vi gjerne fra deg. Kontaktinformasjon finner du p√• v√•r nettside: **https://www.naie.no/**

Sammen kan vi bidra til √• forme et mer rettferdig og transparent AI-landskap i Norge.
