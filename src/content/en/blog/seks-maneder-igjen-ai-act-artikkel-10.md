*February 5, 2026 – Wessel Braakman*

On February 2, Norsk AI-Etikkforening (NAIE) was launched.
On the same day, there were six months left until key parts of the EU’s AI Act enter into force.

Among the many provisions, we find Article 10, which requires identification of biases in high-risk AI systems. The biases must be reduced where possible. In addition, there is a requirement for monitoring after a system has been put into use.

## Article 10: AI ethics from theory to practice

![Article 10](/blog/seks-maneder-igjen-ai-act-artikkel-10/1-artikkel.png)
![Article 10](/blog/seks-maneder-igjen-ai-act-artikkel-10/2-artikkel.png)

[Article 10 ](https://artificialintelligenceact.eu/article/10/) sets requirements that datasets in such AI systems are relevant and representative. And thus AI ethics is no longer a voluntary exercise. For many organizations, Article 10 will bring operational challenges, where among other things it must be clarified:

What does bias mean in our system? 
How can we actually uncover it? 
How often should we test? 
What happens when a system changes over time? 

These are not just legal questions. They affect development, testing and operations. And the questions have no simple answers.

## Six months is not a long time

While winter turns into spring and summer fades away, Norwegian organizations must put in place:

- a shared understanding of what bias entails 
- tests that go beyond performance and accuracy 
- routines for monitoring after production deployment 
- a clear idea of what is sufficient practice 

The obstacles to such a review do not have to be about lack of willingness. It can be about lack of methods, few reference points and limited experience sharing, especially in a Norwegian context.

## The purpose of NAIE

![Article 10](/blog/seks-maneder-igjen-ai-act-artikkel-10/3-blog.png)

Norsk AI-Etikkforening already has experience with testing bias in language models, with a focus on Norwegian language and culture. We are open about our methods and make our findings available continuously, including in a blog with analyses based on a larger dataset.

![Article 10](/blog/seks-maneder-igjen-ai-act-artikkel-10/4-blog.png)

NAIE was created to continue our already ongoing work in a more transparent and structured way. We do not have a definitive answer, but we openly share our experiences measuring biases in AI systems.

Article 10 is about building AI systems that businesses and the public can trust over time. NAIE contributes methodology for implementing ethics in practice.
